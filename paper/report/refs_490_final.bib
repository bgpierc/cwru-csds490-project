
@misc{noauthor_osf_nodate,
	title = {{OSF} {\textbar} {Electroluminescent} ({EL}) {Image} {Dataset} of {PV} {Module} {Under} {Step}-wise {Damp} {Heat} {Exposures}},
	url = {https://osf.io/4qrtv/},
	urldate = {2024-03-01},
	file = {OSF | Electroluminescent (EL) Image Dataset of PV Module Under Step-wise Damp Heat Exposures:/Users/benpierce/Zotero/storage/3PDB7HTQ/4qrtv.html:text/html},
}

@article{karimi_generalized_2020,
	title = {Generalized and mechanistic {PV} module performance prediction from computer vision and machine learning on electroluminescence images},
	volume = {10},
	url = {https://ieeexplore.ieee.org/abstract/document/9050914/},
	number = {3},
	urldate = {2024-03-01},
	journal = {IEEE Journal of Photovoltaics},
	author = {Karimi, Ahmad Maroof and Fada, Justin S. and Parrilla, Nicholas A. and Pierce, Benjamin G. and Koyutürk, Mehmet and French, Roger H. and Braid, Jennifer L.},
	year = {2020},
	note = {Publisher: IEEE},
	pages = {878--887},
}

@inproceedings{pierce_identifying_2020,
	title = {Identifying {Degradation} {Modes} of {Photovoltaic} {Modules} {Using} {Unsupervised} {Machine} {Learning} on {Electroluminescense} {Images}},
	url = {https://ieeexplore.ieee.org/abstract/document/9301021/},
	urldate = {2024-03-01},
	booktitle = {2020 47th {IEEE} {Photovoltaic} {Specialists} {Conference} ({PVSC})},
	publisher = {IEEE},
	author = {Pierce, Benjamin G. and Karimi, Ahmad Maroof and Liu, JiQi and French, Roger H. and Braid, Jennifer L.},
	year = {2020},
	pages = {1850--1855},
}

@article{chen_automated_2022,
	title = {Automated defect identification in electroluminescence images of solar modules},
	volume = {242},
	issn = {0038-092X},
	url = {https://www.sciencedirect.com/science/article/pii/S0038092X22004571},
	doi = {10.1016/j.solener.2022.06.031},
	abstract = {Solar photovoltaic (PV) modules are susceptible to manufacturing defects, mishandling problems or extreme weather events that can limit energy production or cause early device failure. Trained professionals use electroluminescence (EL) images to identify defects in modules, however, field surveys or inline image acquisition can generate millions of EL images, which are infeasible to analyze by rote inspection. We develop a rapid automatic computer vision pipeline (∼0.5 seconds/module) to analyze EL images and identify defects including cracks, intra-cell defects, oxygen-induced defects, and solder disconnections. Defect identification is achieved with a machine learning model (Random Forest, ResNet models and YOLO) trained on 762 manually-labeled EL images of PV modules. We compare model performance on an imbalanced real-world validation set containing 134 EL images and determine that ResNet18 and YOLO are the optimal models; we next evaluated these models on a dedicated testing set (129 module images) with resulting macro F1 scores of 0.83 (ResNet18) and 0.78 (YOLO). Using a field EL survey of a PV power plant damaged in a vegetation fire, we analyze 18,954 EL images (2.4 million cells) and inspect the spatial distribution of defects on the solar modules. The results find increased frequency of ‘crack’, ‘solder’ and ‘intra-cell’ defects on the edges of the solar module closest to the ground after fire. We also find an abnormal increase of striation rings on cells which were assumed to be caused mainly in fabrication process. Our methods are published as open-source software. It can also be used to identify other kinds of defects or process different types of solar cells with minor modification on models by transfer learning.},
	urldate = {2024-03-01},
	journal = {Solar Energy},
	author = {Chen, Xin and Karin, Todd and Jain, Anubhav},
	month = aug,
	year = {2022},
	keywords = {Big data, Computer vision, Deep learning, Electroluminescence image, Solar module defect},
	pages = {20--29},
	file = {ScienceDirect Snapshot:/Users/benpierce/Zotero/storage/84BF6AV7/S0038092X22004571.html:text/html;Submitted Version:/Users/benpierce/Zotero/storage/HWCSSN6R/Chen et al. - 2022 - Automated defect identification in electroluminesc.pdf:application/pdf},
}

@article{deitsch_automatic_2019,
	title = {Automatic classification of defective photovoltaic module cells in electroluminescence images},
	volume = {185},
	issn = {0038-092X},
	url = {https://www.sciencedirect.com/science/article/pii/S0038092X19302014},
	doi = {10.1016/j.solener.2019.02.067},
	abstract = {Electroluminescence (EL) imaging is a useful modality for the inspection of photovoltaic (PV) modules. EL images provide high spatial resolution, which makes it possible to detect even finest defects on the surface of PV modules. However, the analysis of EL images is typically a manual process that is expensive, time-consuming, and requires expert knowledge of many different types of defects. In this work, we investigate two approaches for automatic detection of such defects in a single image of a PV cell. The approaches differ in their hardware requirements, which are dictated by their respective application scenarios. The more hardware-efficient approach is based on hand-crafted features that are classified in a Support Vector Machine (SVM). To obtain a strong performance, we investigate and compare various processing variants. The more hardware-demanding approach uses an end-to-end deep Convolutional Neural Network (CNN) that runs on a Graphics Processing Unit (GPU). Both approaches are trained on 1968 cells extracted from high resolution EL intensity images of mono- and polycrystalline PV modules. The CNN is more accurate, and reaches an average accuracy of 88.42\%. The SVM achieves a slightly lower average accuracy of 82.44\%, but can run on arbitrary hardware. Both automated approaches make continuous, highly accurate monitoring of PV cells feasible.},
	urldate = {2024-03-01},
	journal = {Solar Energy},
	author = {Deitsch, Sergiu and Christlein, Vincent and Berger, Stephan and Buerhop-Lutz, Claudia and Maier, Andreas and Gallwitz, Florian and Riess, Christian},
	month = jun,
	year = {2019},
	keywords = {Deep learning, Defect classification, Electroluminescence imaging, Photovoltaic modules, Regression analysis, Support vector machines, Visual inspection},
	pages = {455--468},
	file = {ScienceDirect Snapshot:/Users/benpierce/Zotero/storage/4F9KEWFV/S0038092X19302014.html:text/html;Submitted Version:/Users/benpierce/Zotero/storage/82YWRF7S/Deitsch et al. - 2019 - Automatic classification of defective photovoltaic.pdf:application/pdf},
}


@article{akram_cnn_2019,
	title = {{CNN} based automatic detection of photovoltaic cell defects in electroluminescence images},
	volume = {189},
	issn = {0360-5442},
	url = {https://www.sciencedirect.com/science/article/pii/S0360544219320146},
	doi = {https://doi.org/10.1016/j.energy.2019.116319},
	abstract = {Automatic defect detection is gaining huge importance in photovoltaic ({PV}) field due to limited application of manual/visual inspection and rising production quantities of {PV} modules. This study is conducted for automatic detection of {PV} module defects in electroluminescence ({EL}) images. We presented a novel approach using light convolutional neural network architecture for recognizing defects in {EL} images which achieves state of the art results of 93.02\% on solar cell dataset of {EL} images. It requires less computational power and time. It can work on an ordinary {CPU} computer while maintaining real time speed. It takes only 8.07 ms for predicting one image. For proposing light architecture, we perform extensive experimentation on series of architectures. Moreover, we evaluate data augmentation operations to deal with data scarcity. Overfitting appears a significant problem; thus, we adopt appropriate strategies to generalize model. The impact of each strategy is presented. In addition, cracking patterns and defects that can appear in {EL} images are reviewed; which will help to label new images appropriately for predicting specific defect types upon availability of large data. The proposed framework is experimentally applied in lab and can help for automatic defect detection in field and industry.},
	pages = {116319},
	journaltitle = {Energy},
	author = {Akram, M. Waqar and Li, Guiqiang and Jin, Yi and Chen, Xiao and Zhu, Changan and Zhao, Xudong and Khaliq, Abdul and Faheem, M. and Ahmad, Ashfaq},
	date = {2019},
	keywords = {Automatic defect detection, Convolutional neural network ({CNN}), Deep learning, Electroluminescence, photovoltaic ({PV}) modules, {PV} cell cracking},
}

@article{DBLP:journals/corr/RonnebergerFB15,
  author       = {Olaf Ronneberger and
                  Philipp Fischer and
                  Thomas Brox},
  title        = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  journal      = {CoRR},
  volume       = {abs/1505.04597},
  year         = {2015},
  url          = {http://arxiv.org/abs/1505.04597},
  eprinttype    = {arXiv},
  eprint       = {1505.04597},
  timestamp    = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{Subramanian2020,
  author = {Subramanian, A.K},
  title = {PyTorch-VAE},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/AntixK/PyTorch-VAE}}
}

@misc{ronneberger2015unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{shekhovtsov2022vae,
      title={VAE Approximation Error: ELBO and Exponential Families}, 
      author={Alexander Shekhovtsov and Dmitrij Schlesinger and Boris Flach},
      year={2022},
      eprint={2102.09310},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{dempster_maximum_1977,
	title = {Maximum {Likelihood} from {Incomplete} {Data} via the {EM} {Algorithm}},
	volume = {39},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2984875},
	abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
	number = {1},
	urldate = {2024-05-06},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
	year = {1977},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {1--38},
	file = {JSTOR Full Text PDF:/home/bgpierce/Zotero/storage/PDK7N934/Dempster et al. - 1977 - Maximum Likelihood from Incomplete Data via the EM.pdf:application/pdf},
}

@article{domingos_few_2012,
	title = {A few useful things to know about machine learning},
	volume = {55},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/2347736.2347755},
	doi = {10.1145/2347736.2347755},
	abstract = {Tapping into the "folk knowledge" needed to advance machine learning applications.},
	number = {10},
	urldate = {2024-05-06},
	journal = {Communications of the ACM},
	author = {Domingos, Pedro},
	month = oct,
	year = {2012},
	pages = {78--87},
	file = {Full Text PDF:/home/bgpierce/Zotero/storage/98APD7HR/Domingos - 2012 - A few useful things to know about machine learning.pdf:application/pdf},
}


@article{szekely_hierarchical_2005,
	title = {Hierarchical {Clustering} via {Joint} {Between}-{Within} {Distances}: {Extending} {Ward}'s {Minimum} {Variance} {Method}},
	volume = {22},
	issn = {1432-1343},
	shorttitle = {Hierarchical {Clustering} via {Joint} {Between}-{Within} {Distances}},
	url = {https://doi.org/10.1007/s00357-005-0012-9},
	doi = {10.1007/s00357-005-0012-9},
	language = {en},
	number = {2},
	urldate = {2024-05-06},
	journal = {Journal of Classification},
	author = {Szekely, Gabor J. and Rizzo, Maria L.},
	month = sep,
	year = {2005},
	keywords = {Hierarchical Cluster, Minimum Variance, Pattern Recognition, Statistical Theory},
	pages = {151--183},
	file = {Full Text PDF:/home/bgpierce/Zotero/storage/XHVL5INX/Szekely and Rizzo - 2005 - Hierarchical Clustering via Joint Between-Within D.pdf:application/pdf},
}


@article{kramer_nonlinear_1991,
	title = {Nonlinear principal component analysis using autoassociative neural networks},
	volume = {37},
	issn = {0001-1541},
	url = {https://ui.adsabs.harvard.edu/abs/1991AIChE..37..233K},
	doi = {10.1002/aic.690370209},
	abstract = {Nonlinear principal component analysis is a novel technique for multivariate data analysis, similar to the well-known method of principal component analysis. NLPCA, like PCA, is used to identify and remove correlations among problem variables as an aid to dimensionality reduction, visualization, and exploratory data analysis. While PCA identifies only linear correlations between variables, NLPCA uncovers both linear and nonlinear correlations, without restriction on the character of the nonlinearities present in the data. NLPCA operates by training a feedforward neural network to perform the identity mapping, where the network inputs are reproduced at the output layer. The network contains an internal "bottleneck" layer (containing fewer nodes than input or output layers), which forces the network to develop a compact representation of the input data, and two additional hidden layers. The NLPCA method is demonstrated using time-dependent, simulated batch reaction data. Results show that NLPCA successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters.},
	urldate = {2024-05-06},
	journal = {AIChE Journal},
	author = {Kramer, Mark A.},
	month = feb,
	year = {1991},
	note = {ADS Bibcode: 1991AIChE..37..233K},
	pages = {233--243},
}

@misc{plumerault_avae_2020,
	title = {{AVAE}: {Adversarial} {Variational} {Auto} {Encoder}},
	shorttitle = {{AVAE}},
	url = {http://arxiv.org/abs/2012.11551},
	doi = {10.48550/arXiv.2012.11551},
	abstract = {Among the wide variety of image generative models, two models stand out: Variational Auto Encoders (VAE) and Generative Adversarial Networks (GAN). GANs can produce realistic images, but they suffer from mode collapse and do not provide simple ways to get the latent representation of an image. On the other hand, VAEs do not have these problems, but they often generate images less realistic than GANs. In this article, we explain that this lack of realism is partially due to a common underestimation of the natural image manifold dimensionality. To solve this issue we introduce a new framework that combines VAE and GAN in a novel and complementary way to produce an auto-encoding model that keeps VAEs properties while generating images of GAN-quality. We evaluate our approach both qualitatively and quantitatively on five image datasets.},
	urldate = {2024-05-06},
	publisher = {arXiv},
	author = {Plumerault, Antoine and Borgne, Hervé Le and Hudelot, Céline},
	month = dec,
	year = {2020},
	note = {arXiv:2012.11551 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: pre-print version of an article to appear in the proceedings of the International Conference on Pattern Recognition (ICPR 2020) in January 2021},
	file = {arXiv Fulltext PDF:/home/bgpierce/Zotero/storage/VKCTGV87/Plumerault et al. - 2020 - AVAE Adversarial Variational Auto Encoder.pdf:application/pdf},
}


@inproceedings{rublee_orb_2011,
	title = {{ORB}: {An} efficient alternative to {SIFT} or {SURF}},
	shorttitle = {{ORB}},
	url = {https://ieeexplore.ieee.org/document/6126544},
	doi = {10.1109/ICCV.2011.6126544},
	abstract = {Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
	urldate = {2024-05-06},
	booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
	author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
	month = nov,
	year = {2011},
	note = {ISSN: 2380-7504},
	keywords = {Boats},
	pages = {2564--2571},
	file = {IEEE Xplore Full Text PDF:/home/bgpierce/Zotero/storage/YM6GHD65/Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:application/pdf},
}


@article{tola_daisy_2010,
	title = {{DAISY}: {An} {Efficient} {Dense} {Descriptor} {Applied} to {Wide}-{Baseline} {Stereo}},
	volume = {32},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0162-8828},
	shorttitle = {{DAISY}},
	url = {http://ieeexplore.ieee.org/document/4815264/},
	doi = {10.1109/TPAMI.2009.77},
	abstract = {In this paper, we introduce a local image descriptor, DAISY, which is very efficient to compute densely. We also present an EM-based algorithm to compute dense depth and occlusion maps from wide-baseline image pairs using this descriptor. This yields much better results in wide-baseline situations than the pixel and correlation-based algorithms that are commonly used in narrowbaseline stereo. Also, using a descriptor makes our algorithm robust against many photometric and geometric transformations. Our descriptor is inspired from earlier ones such as SIFT and GLOH but can be computed much faster for our purposes. Unlike SURF, which can also be computed efficiently at every pixel, it does not introduce artifacts that degrade the matching performance when used densely. It is important to note that our approach is the first algorithm that attempts to estimate dense depth maps from wide-baseline image pairs, and we show that it is a good one at that with many experiments for depth estimation accuracy, occlusion detection, and comparing it against other descriptors on laser-scanned ground truth scenes. We also tested our approach on a variety of indoor and outdoor scenes with different photometric and geometric transformations and our experiments support our claim to being robust against these.},
	language = {en},
	number = {5},
	urldate = {2024-05-06},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Tola, E. and Lepetit, V. and Fua, P.},
	month = may,
	year = {2010},
	pages = {815--830},
	file = {Tola et al. - 2010 - DAISY An Efficient Dense Descriptor Applied to Wi.pdf:/home/bgpierce/Zotero/storage/NQ5W7IFR/Tola et al. - 2010 - DAISY An Efficient Dense Descriptor Applied to Wi.pdf:application/pdf},
}


@article{rosten_faster_2010,
	title = {Faster and better: a machine learning approach to corner detection},
	volume = {32},
	issn = {0162-8828},
	shorttitle = {Faster and better},
	url = {http://arxiv.org/abs/0810.2434},
	doi = {10.1109/TPAMI.2008.275},
	abstract = {The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is importand because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations [Schmid et al 2000]. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection, and using machine learning we derive a feature detector from this which can fully process live PAL video using less than 5\% of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115\%, SIFT 195\%). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and very high quality.},
	number = {1},
	urldate = {2024-05-06},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Rosten, Edward and Porter, Reid and Drummond, Tom},
	month = jan,
	year = {2010},
	note = {arXiv:0810.2434 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {105--119},
	annote = {Comment: 35 pages, 11 figures},
	file = {arXiv Fulltext PDF:/home/bgpierce/Zotero/storage/CPBQLD4F/Rosten et al. - 2010 - Faster and better a machine learning approach to .pdf:application/pdf},
}


@inproceedings{alcantarilla_kaze_2012,
	address = {Berlin, Heidelberg},
	title = {{KAZE} {Features}},
	isbn = {978-3-642-33783-3},
	abstract = {In this paper, we introduce KAZE features, a novel multiscale 2D feature detection and description algorithm in nonlinear scale spaces. Previous approaches detect and describe features at different scale levels by building or approximating the Gaussian scale space of an image. However, Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same degree both details and noise, reducing localization accuracy and distinctiveness. In contrast, we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering. In this way, we can make blurring locally adaptive to the image data, reducing noise but retaining object boundaries, obtaining superior localization accuracy and distinctiviness. The nonlinear scale space is built using efficient Additive Operator Splitting (AOS) techniques and variable conductance diffusion. We present an extensive evaluation on benchmark datasets and a practical matching application on deformable surfaces. Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space, but comparable to SIFT, our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods.},
	booktitle = {Computer {Vision} – {ECCV} 2012},
	publisher = {Springer Berlin Heidelberg},
	author = {Alcantarilla, Pablo Fernández and Bartoli, Adrien and Davison, Andrew J.},
	editor = {Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
	year = {2012},
	pages = {214--227},
}


@article{haralick_textural_1973,
	title = {Textural {Features} for {Image} {Classification}},
	volume = {SMC-3},
	issn = {2168-2909},
	url = {https://ieeexplore.ieee.org/document/4309314},
	doi = {10.1109/TSMC.1973.4309314},
	abstract = {Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.},
	number = {6},
	urldate = {2024-05-06},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Haralick, Robert M. and Shanmugam, K. and Dinstein, Its'Hak},
	month = nov,
	year = {1973},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics},
	keywords = {Application software, Crops, Earth, Humans, Image classification, Image resolution, Piecewise linear techniques, Satellites, Spatial resolution, Testing},
	pages = {610--621},
	file = {IEEE Xplore Full Text PDF:/home/bgpierce/Zotero/storage/GRLESMEJ/Haralick et al. - 1973 - Textural Features for Image Classification.pdf:application/pdf},
}

@article{karimi_generalized_2020,
	title = {Generalized and {Mechanistic} {PV} {Module} {Performance} {Prediction} {From} {Computer} {Vision} and {Machine} {Learning} on {Electroluminescence} {Images}},
	volume = {10},
	issn = {2156-3403},
	url = {https://ieeexplore.ieee.org/abstract/document/9050914},
	doi = {10.1109/JPHOTOV.2020.2973448},
	abstract = {Electroluminescence (EL) imaging of photovoltiac (PV) modules offers high-speed, high-resolution information about device performance, affording opportunities for greater insight and efficiency in module characterization across manufacturing, research and development, and power plant operations and management. Predicting module electrical properties from EL image features is a critical step toward these applications. In this article, we demonstrate quantification of both generalized and performance mechanism-specific EL image features, using pixel intensity-based and machine learning classification algorithms. From EL image features, we build predictive models for PV module power and series resistance, using time-series current-voltage (I-V) and EL data obtained stepwise on five brands of modules spanning three Si cell types through two accelerated exposures: damp heat (DH) (85°C/85\% RH) and thermal cycling (TC) (IEC 61215). In total, 195 pairs of EL images and I-V characteristics were analyzed, yielding 11700 individual PV cell images. A convolutional neural network was built to classify cells by the severity of busbar corrosion with high accuracy (95\%). Generalized power predictive models estimated the maximum power of PV modules from EL images with high confidence and an adjusted-R2 of 0.88, across all module brands and cell types in extended DH and TC exposures. Mechanistic degradation prediction was demonstrated by quantification of busbar corrosion in EL images of three module brands in DH, and subsequent modeling of series resistance using these mechanism-specific EL image features. For modules exhibiting busbar corrosion, we demonstrated series resistance predictive models with adjusted-R2 of up to 0.73.},
	number = {3},
	urldate = {2024-05-06},
	journal = {IEEE Journal of Photovoltaics},
	author = {Karimi, Ahmad Maroof and Fada, Justin S. and Parrilla, Nicholas A. and Pierce, Benjamin G. and Koyutürk, Mehmet and French, Roger H. and Braid, Jennifer L.},
	month = may,
	year = {2020},
	note = {Conference Name: IEEE Journal of Photovoltaics},
	keywords = {Computer architecture, Computer vision, convolutional neural network (CNN), corrosion, Corrosion, damp heat (DH), Degradation, electroluminescence (EL) imaging, Feature extraction, Machine learning, Microprocessors, photovoltiac (PV) module degradation, Resistance, thermal cycling (TC)},
	pages = {878--887},
}

